{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pang-lee/Siamese-twins-network-with-3DCNN/blob/main/3dcnn_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838f91d9",
      "metadata": {
        "id": "838f91d9"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3afbbb",
      "metadata": {
        "id": "2e3afbbb"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('AGG')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import (Activation, Conv3D, Dense, Dropout, Flatten,\n",
        "                          MaxPooling3D, concatenate,Lambda,BatchNormalization)\n",
        "from keras.layers.activation import LeakyReLU\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00cba41c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "00cba41c"
      },
      "outputs": [],
      "source": [
        "import videoto3d\n",
        "from tqdm import tqdm\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84627b1",
      "metadata": {
        "id": "a84627b1"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, result_dir):\n",
        "    plt.plot(history.history['accuracy'], marker='.')\n",
        "    plt.plot(history.history['val_accuracy'], marker='.')\n",
        "    plt.title('model accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.grid()#生成網格\n",
        "    plt.legend(['acc', 'val_acc'], loc='lower right')\n",
        "    plt.savefig(os.path.join(result_dir, 'model_accuracy.png'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(history.history['loss'], marker='.')\n",
        "    plt.plot(history.history['val_loss'], marker='.')\n",
        "    plt.title('model loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.grid()\n",
        "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
        "    plt.savefig(os.path.join(result_dir, 'model_loss.png'))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f918769",
      "metadata": {
        "id": "8f918769"
      },
      "outputs": [],
      "source": [
        "def save_history(history, result_dir):\n",
        "    loss = history.history['loss']\n",
        "    acc = history.history['accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    nb_epoch = len(acc)\n",
        "\n",
        "    with open(os.path.join(result_dir, 'result.txt'), 'w') as fp:\n",
        "        fp.write('epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n')\n",
        "        for i in range(nb_epoch):\n",
        "            fp.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
        "                i, loss[i], acc[i], val_loss[i], val_acc[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4affb3",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "ad4affb3"
      },
      "outputs": [],
      "source": [
        "def loaddata(video_dir, vid3d, nclass, result_dir, color=False, skip=True):\n",
        "    #os.listdir()用於返回指定文件夾中的文件或文件夾名字列表，在這是dataset文件夾\n",
        "    #裡面存放的是視頻數據\n",
        "    files = os.listdir(video_dir)\n",
        "    # X存放的是五維數組，各個維數代表(視頻編號，幀高，幀寬，通道數(RGB)，一個視頻提取的幀數)，\n",
        "    # 例如(402,32,32,3,16)是總共402個視頻，每個視頻提取16幀，每個幀是32x32x3的圖像\n",
        "    X = []\n",
        "    #labels是每個視頻對應的標籤，402個視頻就有402個標籤\n",
        "    labels = []\n",
        "    #labellist是標籤的種類，402個視頻，但是只有3個種類，那麼labellist的shape就是3\n",
        "    labellist = []\n",
        "\n",
        "    pbar = tqdm(total=len(files))#進度條\n",
        "\n",
        "    for filename in files:#如果用UCF-101資料夾，files就會有101個不同類別的視頻文件夾，對這101個文件夾掃過一輪\n",
        "        print(filename)\n",
        "        pbar.update(1)#更新進度條\n",
        "        if filename == '.DS_Store':\n",
        "            continue\n",
        "        namelist = os.path.join(video_dir, filename)\n",
        "        files2 = os.listdir(namelist)#files2是一個文件夾中的視頻，一個array\n",
        "        for  files3 in  files2:#對一個類別的文件夾中所有視頻遍歷\n",
        "            name = os.path.join(namelist,files3)\n",
        "            print(\"dir is \",name)\n",
        "            label = vid3d.get_UCF_classname(files3)#取得視頻對應的類別名\n",
        "            if label not in labellist:#將新的類別名放入labellist中\n",
        "                if len(labellist) >= nclass:\n",
        "                    continue\n",
        "                labellist.append(label)#每一個視頻對應的類別都要放入label中\n",
        "            labels.append(label)\n",
        "            # 將每個視頻處理後得到的四維數組合併,形成五維的X。\n",
        "            X.append(vid3d.video3d(name, color=color, skip=skip))\n",
        "\n",
        "    pbar.close()#關閉進度條\n",
        "    with open(os.path.join(result_dir, 'classes.txt'), 'w') as fp:\n",
        "        for i in range(len(labellist)):\n",
        "            fp.write('{}\\n'.format(labellist[i]))\n",
        "\n",
        "    for num, label in enumerate(labellist):\n",
        "        for i in range(len(labels)):\n",
        "            if label == labels[i]:\n",
        "                labels[i] = num#如果只分三類，那麼labels只有三種0，1，2\n",
        "    if color:\n",
        "        return np.array(X).transpose((0, 2, 3, 4, 1)), labels#將X的1軸放在最後，這一維表示每個視頻的15幀\n",
        "    else:\n",
        "        return np.array(X).transpose((0, 2, 3, 1)), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520d1b68",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "520d1b68"
      },
      "outputs": [],
      "source": [
        "# 兩個tensor=t1,t2\n",
        "# 歐幾里得距離 = sqrt(sum(square(t1-t2)))\n",
        "def euclidean_distance(vects): ##網路上找的，待研究\n",
        "    \"\"\"求兩個向量之間的歐幾里得距離。\n",
        "\n",
        "    Arguments:\n",
        "        vectos: 包含兩個相同長度的張量的列表。\n",
        "\n",
        "    Returns:\n",
        "        包含向量之間歐式距離（作為浮點值）的張量。\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5819b67",
      "metadata": {
        "id": "e5819b67"
      },
      "outputs": [],
      "source": [
        "def Loss(margin=1): #網路上找的，待研究\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "    Arguments:\n",
        "        margin: Integer, defines the baseline for distance for which pairs\n",
        "                should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "    Returns:\n",
        "        'constrastive_loss' function with data ('margin') attached.\n",
        "    \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "        Arguments:\n",
        "            y_true: List of labels, each label is of type float32.\n",
        "            y_pred: List of predictions of same length as of y_true,\n",
        "                    each label is of type float32.\n",
        "\n",
        "        Returns:\n",
        "            A tensor containing constrastive loss as floating point value.\n",
        "        \"\"\"\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea08b369",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "ea08b369"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='simple 3D convolution for action recognition')\n",
        "    parser.add_argument('--batch', type=int, default=128)\n",
        "    parser.add_argument('--epoch', type=int, default=100)\n",
        "    parser.add_argument('--videos', type=str, default='UCF101',\n",
        "                        help='directory where videos are stored')\n",
        "    parser.add_argument('--nclass', type=int, default=101)\n",
        "    parser.add_argument('--output', type=str, required=True)\n",
        "    parser.add_argument('--color', type=bool, default=False)\n",
        "    parser.add_argument('--skip', type=bool, default=True)\n",
        "    parser.add_argument('--depth', type=int, default=10)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    img_rows, img_cols, frames = 32, 32, args.depth\n",
        "    channel = 3 if args.color else 1\n",
        "    fname_npz = 'dataset_{}_{}_{}.npz'.format(\n",
        "        args.nclass, args.depth, args.skip)\n",
        "\n",
        "    vid3d = videoto3d.Videoto3D(img_rows, img_cols, frames)\n",
        "    nb_classes = args.nclass\n",
        "    if os.path.exists(fname_npz):\n",
        "        loadeddata = np.load(fname_npz)\n",
        "        X, Y = loadeddata[\"X\"], loadeddata[\"Y\"]\n",
        "    else:\n",
        "        x, y = loaddata(args.videos, vid3d, args.nclass,\n",
        "                        args.output, args.color, args.skip)\n",
        "        X = x.reshape((x.shape[0], img_rows, img_cols, frames, channel))\n",
        "        Y = np_utils.to_categorical(y, nb_classes)\n",
        "\n",
        "        X = X.astype('float32')\n",
        "        np.savez(fname_npz, X=X, Y=Y)\n",
        "        print('Saved dataset to dataset.npz.')\n",
        "    print('X_shape:{}\\nY_shape:{}'.format(X.shape, Y.shape))\n",
        "\n",
        "\n",
        "    # 3DCNN網路架構建立\n",
        "    input_ = Input(shape=(X.shape[1:]))\n",
        "    \n",
        "    model_3dcnn = Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding='same')(input_)\n",
        "    model_3dcnn = Conv3D(32, kernel_size=(3, 3, 3), activation='softmax', padding='same')(model_3dcnn)\n",
        "    model_3dcnn = MaxPooling3D(pool_size=(3, 3, 3), padding='SAME')(model_3dcnn)\n",
        "    model_3dcnn = Dropout(0.25)(model_3dcnn)\n",
        "    model_3dcnn = Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same')(model_3dcnn)\n",
        "    model_3dcnn = Conv3D(64, kernel_size=(3, 3, 3), activation='softmax', padding='same')(model_3dcnn)\n",
        "    model_3dcnn = MaxPooling3D(pool_size=(3, 3, 3), padding='SAME')(model_3dcnn)\n",
        "    model_3dcnn = Dropout(0.25)(model_3dcnn)\n",
        "    model_3dcnn = Flatten()(model_3dcnn)\n",
        "    model_3dcnn = Dense(512, activation='sigmoid')(model_3dcnn)\n",
        "    model_3dcnn = Dropout(0.5)(model_3dcnn)\n",
        "    output_ = Dense(nb_classes, activation='softmax')(model_3dcnn)\n",
        "   \n",
        "    cnn3d_model = Model(input_ ,output_)\n",
        "    plot_model(cnn3d_model, show_shapes=True,\n",
        "               to_file=os.path.join(args.output, 'model_3dcnn.png'))\n",
        "    \n",
        "    #建立孿生網路\n",
        "    input_1 =  Input(shape=(X.shape[1:]))\n",
        "    input_2 =  Input(shape=(X.shape[1:]))\n",
        "    \n",
        "    tower_1 = cnn3d_model(input_1)\n",
        "    tower_2 = cnn3d_model(input_2)\n",
        "    \n",
        "    merge_layer = Lambda(euclidean_distance)([tower_1, tower_2])\n",
        "    normal_layer = BatchNormalization()(merge_layer)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\")(normal_layer)\n",
        "    \n",
        "    siamese_model =Model([input_1, input_2], output_layer)\n",
        "\n",
        "    siamese_model.compile(loss=Loss(margin=1),\n",
        "                  optimizer='RMSprop', metrics=['accuracy'])\n",
        "    siamese_model.summary()\n",
        "\n",
        "    plot_model(siamese_model, show_shapes=True,\n",
        "               to_file=os.path.join(args.output, 'model_siamese.png'))#畫出模型架構圖\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=43)\n",
        "\n",
        "    history = siamese_model.fit([X_train,X_train],Y_train, validation_data=([X_test,X_test], Y_test), batch_size=args.batch,\n",
        "                        epochs=args.epoch, verbose=1, shuffle=True)#verbose=1表示輸出進度條信息， shuffle=True訓練過程打亂輸入樣本順序\n",
        "    siamese_model.evaluate([X_test,X_test], Y_test, verbose=0)#verbose=0表示不輸出日誌信息\n",
        "    model_json = siamese_model.to_json()\n",
        "    if not os.path.isdir(args.output):\n",
        "        os.makedirs(args.output)\n",
        "    with open(os.path.join(args.output, 'ucf101_3dcnnmodel.json'), 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "    siamese_model.save_weights(os.path.join(args.output, 'ucf101_3dcnnmodel.hd5'))\n",
        "\n",
        "    loss, acc = siamese_model.evaluate([X_test,X_test], Y_test, verbose=0)\n",
        "    print('Test loss:', loss)\n",
        "    print('Test accuracy:', acc)\n",
        "    print(history.history.keys())\n",
        "    plot_history(history, args.output)\n",
        "    save_history(history, args.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff07308",
      "metadata": {
        "id": "0ff07308"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "name": "3dcnn_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}